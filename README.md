# Proposal for implementing the collection of metrics 

As the Netherlands eScience Center grows, keeping track of all the things we do is becoming increasingly difficult. This is a problem, for example for:

1. Directors, who need to inform themselves about the state of the organization in order to steer the organization effectively, 
1. Program Managers, who need to know the history of projects,
1. Community Managers, who want to know what is being worked on,
1. Policy Advisors, who need to prepare various reports
1. etc.

This document outlines an approach for keeping track of various metrics. Some key points of the proposed approach are:

1. The list of what we want to keep track of is changable -- it will never be "done"
1. The implementation of how we track metrics is changable -- it will never be "done"
1. The successful implementation of the approach outlined below requires some technical skills, for example for querying APIs, meaningfully aggregating data, and presenting the data as visualizations, but also requires a good understanding of what is needed, for example with respect to which categories of the Self-Evaluation Protocol need to be covered, what the narratives will be for each of these, and how our efforts should be distributed over the various categories.

## General approach

When planning the project, the project stakeholders should discuss which metrics are meaningful to them given the nature of the project. A list of metrics will be provided. The list of metrics can be extended if needed--in fact, such change is expected, and the directors should encourage all employees to help create a meaningful collection covering all aspects of our work, both technical and non-technical. 

Based on the list, the project stakeholders can come to an agreement with the Program Managers, who will record the list of metrics. The project stakeholders and the Program Managers will periodically review the metrics document, making changes if needed. The list of metrics needs to be kept in a public place, preferably close to where the project output lives. This will help bring focus to the work being done in the project.

## How can people propose new metrics?

The preferred way of proposing a new metric is via GitHub's issue tracker on the repository dedicated to metrics collection at NLeSC https://github.com/nlesc/metrics. When you make a new issue there, you'll be shown the following:

![issue-types](https://user-images.githubusercontent.com/4558105/157683671-dc9bb5d8-498b-4556-b3c2-abb2d2d1f0ea.png)

After choosing _New metric_, you will be show the following issue template:

![issue-template](https://user-images.githubusercontent.com/4558105/157683690-b7408934-118d-4723-8906-c2aa3cdade79.png)

The person proposing a new metric can simply fill in the various sections and be move on with their life. Making issues on GitHub ensures that there is a public record of what was proposed, what points were raised in the ensuing discussion, and whether or not the proposal was added as a new metric.

For a small set of people within the Center, making issues on GitHub is not convenient. For them, simply writing an email to the Program Managers with a description of the proposed idea suffices; Program Managers can then make the issue in their name. 

## Who can propose new metrics?

In principle, anybody can propose new metrics, but the Program Managers will judge if a proposed metric is a meaningful addition to the existing list of metrics. In accepting a metric, the Program Managers must weigh the benefit of any new insights the proposed metric will bring against the cost of the required effort.

## Some examples

...
